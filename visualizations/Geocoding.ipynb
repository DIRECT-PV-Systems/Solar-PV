{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b4c689",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e5963",
   "metadata": {},
   "source": [
    "The entire Tracking the Sun dataset contains over 1 million points of data for solar cell systems in the United States. In order to set up the dataset for plotting, the locations of the solar cell systems need to be geocoded. Using the geocoding service Nominatim in combination with geopy, the coordinates of each solar cell system will be found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe2e8d",
   "metadata": {},
   "source": [
    "## Geocoding: Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b3f4c",
   "metadata": {},
   "source": [
    "First, the user will import the geocode python file to enable access to the functions to geocode a given dataset. The data file path needs to be specified and passed into the geocoding function. This notebook will walk the user through how to use the geocoding program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6554b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoding\n",
    "from geocoding import read_data\n",
    "from geocoding import find_unique_cities\n",
    "from geocoding import create_save_files\n",
    "from geocoding import geocode_unique\n",
    "from geocoding import assign_lat_long_columns\n",
    "from geocoding import geocode_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2864bd44",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Solar-PV/data/TTS_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_705/1179748731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Solar-PV/data/TTS_sample.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Solar-PV/visualizations/geocoding/geocoding.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#reading in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#check that 'state' column exists in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Solar-PV/data/TTS_sample.csv'"
     ]
    }
   ],
   "source": [
    "data_file_path = 'Solar-PV/data/TTS_sample.csv'\n",
    "data = read_data(data_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0de2f",
   "metadata": {},
   "source": [
    "Geocoding the entire dataset line by line would take over 7 days for 1 million datapoints. So, instead of doing this, only the unique locations are geocoded so that computing time/power isn't wasted on duplicate locations. In this example, the number of unique cities is about 100 less than the total number of cities in the original dataset, thus the amount of cities is geocode is reduced by a third. Using this method on the full dataset results in only about 18% of the datapoints needing to be geocoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae68a7b",
   "metadata": {},
   "source": [
    "The find_unique_cities function creates a datframe of the unique cities in the dataset and preps the locations for geocoding by creating a column 'city_state_country'. This relies on the the original dataframe haivng columns for the city and state and assumign all location are in the USA. The reason for this is that it makes using the geocoding service, Nominatim, more accurate. Without the country specificied there is a chance the geocoding will pick city with the same name in the wrong country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9281fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cities = find_unique_cities(data)\n",
    "unique_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd08f98",
   "metadata": {},
   "source": [
    "If it's the user's first time running geocoding on their data, they should use the the create_save_files function to create blank csv files to store the geocoding progress as its runs. One file is used to store the geocoding data and one file is used to store cities that result in geocode errors. Many of these errors are due to typos in the city names in the original dataset. The purpose of collecting these is so the user can go back and fix the dataset manually after this code runs if they wish.\n",
    "\n",
    "WARNING: Running this function after the geocoding is part of the way through will delete the progress. Only run this once before geocoding a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_save_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43132f0",
   "metadata": {},
   "source": [
    "The geocode_unique function is used to geocode all the unique cities in the original dataset and save the progress as it goes (through the geocode_save function) as well as the cities that result in errors. It takes the unique cities dataframe as an arguement and returns a dataframe with the unique cities geocoded. It also saves this as a .csv as well for reference.\n",
    "\n",
    "Note: If the geocoding below is interrupted, the user can simply run the cell below again and the geocoding will pickup where it left off. (Again, do NOT run the create_save_files function at this stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1fe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_geo_df = geocode_unique(unique_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_geo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9d175",
   "metadata": {},
   "source": [
    "Latitude and longitude coordinates are broken out into two seperate columns through the assign_lat_long_columns function. This makes analyzing and plotting the data easier down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfce39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_geo_df = assign_lat_long_columns(unique_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38deb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_geo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be487844",
   "metadata": {},
   "source": [
    "Finally, the full dataset is geocoded by running the geocode_full function which uses the dataframe of unique cities with latitude and longitude values to assing values to every location in the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = geocode_full(data, unique_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['city_state_country', 'latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2106bb2d",
   "metadata": {},
   "source": [
    "## Geocoding: One Shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3bd341",
   "metadata": {},
   "source": [
    "To geocode the dataset without seeing the step by step resulsts run create_save files and geocode_go. The output is saved to 'TTS_fully_geocoded_sample.csv' which is a the original data with the latitude and longitude coordinates added for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoding\n",
    "from geocoding import create_save_files\n",
    "from geocoding import geocode_go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb64408",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_save_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91240f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_state_country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C., DC, USA</td>\n",
       "      <td>38.895037</td>\n",
       "      <td>-77.036543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCEANSIDE, CA, USA</td>\n",
       "      <td>33.195870</td>\n",
       "      <td>-117.379483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>St. George, UT, USA</td>\n",
       "      <td>37.104153</td>\n",
       "      <td>-113.584131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Narberth, PA, USA</td>\n",
       "      <td>40.008446</td>\n",
       "      <td>-75.260460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAKLAND, CA, USA</td>\n",
       "      <td>37.804456</td>\n",
       "      <td>-122.271356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Etna, NH, USA</td>\n",
       "      <td>43.692849</td>\n",
       "      <td>-72.221756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Falmouth, MA, USA</td>\n",
       "      <td>43.729525</td>\n",
       "      <td>-70.241993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Naugatuck, CT, USA</td>\n",
       "      <td>41.486019</td>\n",
       "      <td>-73.050943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Lititz, PA, USA</td>\n",
       "      <td>40.157125</td>\n",
       "      <td>-76.307210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Bronx, NY, USA</td>\n",
       "      <td>40.846651</td>\n",
       "      <td>-73.878594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city_state_country   latitude   longitude\n",
       "0    Washington D.C., DC, USA  38.895037  -77.036543\n",
       "1          OCEANSIDE, CA, USA  33.195870 -117.379483\n",
       "2         St. George, UT, USA  37.104153 -113.584131\n",
       "3           Narberth, PA, USA  40.008446  -75.260460\n",
       "4            OAKLAND, CA, USA  37.804456 -122.271356\n",
       "..                        ...        ...         ...\n",
       "304             Etna, NH, USA  43.692849  -72.221756\n",
       "305         Falmouth, MA, USA  43.729525  -70.241993\n",
       "306        Naugatuck, CT, USA  41.486019  -73.050943\n",
       "307           Lititz, PA, USA  40.157125  -76.307210\n",
       "308            Bronx, NY, USA  40.846651  -73.878594\n",
       "\n",
       "[309 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = geocode_go('data/TTS_sample.csv')\n",
    "data[['city_state_country', 'latitude', 'longitude']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
